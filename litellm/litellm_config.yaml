# ==============================================================================
# JUGGERNAUT LiteLLM Proxy Configuration
# ==============================================================================
# Multi-provider routing: OpenRouter (primary) → Anthropic (fallback) → OpenAI (fallback)
# All three share model_name "openrouter/auto" so LiteLLM fails over automatically.
# Workers request "openrouter/auto" — no code changes needed.
# ==============================================================================

model_list:
  # ── OpenRouter (primary — existing provider, smart routing) ──
  - model_name: "openrouter/auto"
    litellm_params:
      model: "openrouter/auto"
      api_key: "os.environ/OPENROUTER_API_KEY"
      api_base: "https://openrouter.ai/api/v1"
      max_tokens: 8192
    model_info:
      description: "Primary — OpenRouter smart routing"

  # ── Anthropic direct (fallback 1 — no markup) ──
  - model_name: "openrouter/auto"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "os.environ/ANTHROPIC_API_KEY"
      max_tokens: 8192
    model_info:
      description: "Fallback 1 — Anthropic direct (no markup)"

  - model_name: "anthropic/claude-sonnet-4-20250514"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "os.environ/ANTHROPIC_API_KEY"
      max_tokens: 8192

  - model_name: "anthropic/claude-3-haiku-20240307"
    litellm_params:
      model: "anthropic/claude-3-haiku-20240307"
      api_key: "os.environ/ANTHROPIC_API_KEY"
      max_tokens: 4096

  # ── OpenAI direct (fallback 2 — no markup) ──
  - model_name: "openrouter/auto"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "os.environ/OPENAI_API_KEY"
      max_tokens: 8192
    model_info:
      description: "Fallback 2 — OpenAI direct (no markup)"

  - model_name: "openai/gpt-4o"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "os.environ/OPENAI_API_KEY"
      max_tokens: 8192

  - model_name: "openai/gpt-4o-mini"
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: "os.environ/OPENAI_API_KEY"
      max_tokens: 4096

litellm_settings:
  num_retries: 2
  retry_after: 5
  request_timeout: 120
  # Budget controls
  max_budget: 50.0
  budget_duration: "1d"
  set_verbose: false

general_settings:
  # master_key: "os.environ/LITELLM_MASTER_KEY"  # Re-enable when adding auth
  health_check: true
  allow_routes_without_auth:
    - "/health"
    - "/health/liveliness"
    - "/health/readiness"
